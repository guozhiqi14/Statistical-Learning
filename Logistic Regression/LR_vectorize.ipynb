{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data..\n",
      "read data cost  7.15201401711  second \n",
      "\n",
      "Start training..\n",
      "Training cost  0.474374055862  second \n",
      "\n",
      "Start predicting..\n",
      "Predicting cost  3.3655128479  second \n",
      "\n",
      "Accuracy is  0.97987012987\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self,max_iteration = 5000, learning_rate = 0.00001):\n",
    "        self.max_iteration = max_iteration\n",
    "        self.learning_rate = learning_rate #leanring rate in gradient descend \n",
    "        \n",
    "    def predict_(self,x):\n",
    "        wx = np.dot(self.w,x)\n",
    "        #print wx\n",
    "        \n",
    "        p_1 = np.exp(wx)/(1+np.exp(wx))\n",
    "        p_0 = 1/(1+np.exp(wx))\n",
    "        #print self.w\n",
    "        #print (p_1,p_0)\n",
    "        \n",
    "        if p_1 >= p_0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def train(self,features,labels):\n",
    "        self.w = [0.0] * (len(features[0])+1)  #w=(w1,w2,...,wn,b)^T, initialize as all 0's\n",
    "        \n",
    "        \n",
    "        #SGD\n",
    "        iteration = 0 \n",
    "        correct_count = 0\n",
    "        \n",
    "        while iteration < self.max_iteration:\n",
    "            index = np.random.choice(len(features),1)[0]\n",
    "            x = features[index]\n",
    "            #x.append(1)  \n",
    "            x = np.append(x,1) #x=(x1,x2,....,xn,1)^T\n",
    "            y = labels[index]\n",
    "            \n",
    "            \n",
    "            gradient = y*x - x * np.exp(np.dot(self.w,x))  / (1+np.exp(np.dot(self.w,x)))\n",
    "            \n",
    "            self.w = self.w - self.learning_rate*(-1*gradient) #哇一个负号要哭了...\n",
    "            iteration +=1\n",
    "             \n",
    "    \n",
    "    def predict(self,features):\n",
    "        labels = []\n",
    "        \n",
    "        for feature in features:\n",
    "            x = list(feature)\n",
    "            x.append(1)\n",
    "            \n",
    "            labels.append(self.predict_(x))\n",
    "        return labels\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    print 'Start read data..'\n",
    "    time1 = time.time()\n",
    "    data = pd.read_csv('train_binary.csv')\n",
    "    \n",
    "    data = data.values\n",
    "    features = data[:,1:]\n",
    "    labels   = data[:,0]\n",
    "    \n",
    "     # 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33)\n",
    "                                                                                \n",
    "    time2 = time.time()\n",
    "    print 'read data cost ',time2 - time1,' second','\\n'\n",
    "    \n",
    "    \n",
    "    print 'Start training..'\n",
    "    LR = LogisticRegression()\n",
    "    LR.train(train_features,train_labels)\n",
    "\n",
    "    time3 = time.time()\n",
    "    print 'Training cost ', time3-time2, ' second', '\\n'\n",
    "    \n",
    "    print 'Start predicting..'\n",
    "    test_predict = LR.predict(test_features)\n",
    "    time4 = time.time()\n",
    "    print 'Predicting cost ', time4-time3, ' second', '\\n'\n",
    "    \n",
    "    score = accuracy_score(test_predict,test_labels)\n",
    "    print'Accuracy is ', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
