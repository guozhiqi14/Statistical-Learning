{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between ID3 and C4.5:\n",
    "* ID3 use information gain while C4.5 use information gain ratio\n",
    "* Information gain is depending on training data, does not have \"absolute\" meaning. While use information gain ratio we could solve this.\n",
    "* $g_r(D,A) = \\frac{g(D,A)}{SplitInfo(D,A)}$ \n",
    "* $SplitInfo(D,A) = -\\sum_{j=1}^{J} \\frac{|S_j|}{|S|} log\\frac{|S_j|}{|S|}$, where J is splitting the dataset into J partitions.\n",
    "* 样本量巨大，其Splite_info会趋向无穷大，则gain_ratio趋向无穷小  \n",
    "* 当存在|Di| ≈ |D|时，split_info将非常小（可能等于0），从而导致增益比例异常大，改进方法是计算每个属性的信息增益，对于超过平均信息增益的属性再进一步根据增益比例来选取属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        logging.debug('start %s()' % func.__name__)\n",
    "        ret = func(*args, **kwargs)\n",
    "        \n",
    "        end_time= time.time()\n",
    "        logging.debug('end %s(), cost %s seconds' % (func.__name__, end_time-start_time))\n",
    "        \n",
    "        return ret\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    raw_data = pd.read_csv('/Users/guozhiqi-seven/Documents/Statistical Learning/Decision Tree/train.csv',header=0) \n",
    "    data = raw_data.values\n",
    "    \n",
    "    img = data[:,1:]\n",
    "    labels = data[:,0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#直接用二值化之后的dataset (cv2 under python3 is available)\n",
    "features = np.loadtxt('features.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = features[:500]\n",
    "labels = labels[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2/3 Training set\n",
    "#1/3 Testing  set\n",
    "train_features,test_features,train_labels,test_labels = train_test_split(features,labels,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self,node_type,Class=None,feature=None):\n",
    "        self.node_type = node_type\n",
    "        self.Class = Class\n",
    "        self.feature = feature\n",
    "        self.dict = {}  #不需要构造新的数据类型来存储决策树，使用字典dict即可方便的存储节点信息\n",
    "    def add_tree(self,val,tree):\n",
    "        self.dict[val]=tree\n",
    "    def predict(self,features):\n",
    "        if self.node_type == 'leaf':\n",
    "            return self.Class\n",
    "        tree = self.dict[features[self.feature]]\n",
    "        \n",
    "        return tree.predict(features)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(x):\n",
    "    '''\n",
    "    calculate entropy\n",
    "    x: labels\n",
    "    '''\n",
    "    \n",
    "    #H(X) = -sum(p_i * log(p_i))\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    entropy = 0.0\n",
    "    \n",
    "    for x_value in x_value_list:\n",
    "        p = float(x[x==x_value].shape[0]) / x.shape[0]\n",
    "        log_p = np.log2(p)\n",
    "        \n",
    "        entropy -= p*log_p\n",
    "    \n",
    "    return entropy #return啊你倒是return啊你妹..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_condition_entropy(x,y):\n",
    "    '''\n",
    "    conditional entropy H(y|x)\n",
    "    \n",
    "    x:feature\n",
    "    y:label\n",
    "    '''\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    entropy = 0.0\n",
    "    \n",
    "    for x_value in x_value_list:\n",
    "        sub_y = y[x==x_value]\n",
    "        temp_entropy = calc_entropy(sub_y)\n",
    "        entropy += (float(sub_y.shape[0]) / y.shape[0]) * temp_entropy\n",
    "        #print float(sub_y.shape[0]) / y.shape[0]\n",
    "    \n",
    "    return entropy #return啊你倒是return啊你妹...\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_info(x,y):\n",
    "    '''\n",
    "    split information/ intrinsic information\n",
    "    x:feature\n",
    "    y:label\n",
    "    '''\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    split_info = 0.0\n",
    "    \n",
    "    for x_value in x_value_list:\n",
    "        sub_y = y[x==x_value]\n",
    "        split_info += float(sub_y.shape[0])/y.shape[0] * np.log2(float(sub_y.shape[0]/y.shape[0]))\n",
    "        #print np.log2(float(sub_y.shape[0])/y.shape[0])\n",
    "    return -split_info   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy_g(x,y):\n",
    "    '''\n",
    "    g(D,A) = H(D) - H(D|A)\n",
    "    '''\n",
    "    base_entropy = calc_entropy(y)\n",
    "    condition_entropy = calc_condition_entropy(x,y)\n",
    "    \n",
    "    entropy_g = base_entropy - condition_entropy\n",
    "    \n",
    "    return entropy_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@log\n",
    "def train(train_set,train_label,features,epsilon):\n",
    "    return recurse_train(train_set,train_label,features,epsilon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurse_train(train_set,train_label,features,epsilon):\n",
    "    global total_class\n",
    "    \n",
    "    LEAF = 'leaf'\n",
    "    INTERNAL = 'internal'\n",
    "    \n",
    "    #Step1: 如果train_set所有实例属于同一类C_k\n",
    "    label_set = set(train_label)\n",
    "    \n",
    "    if len(label_set) == 1:\n",
    "        return Tree(LEAF,Class = label_set.pop())\n",
    "    \n",
    "    #Step2: 如果feature为空\n",
    "    (max_class,max_len)=max([(i,len(filter(lambda x: x==i, train_label))) for i in xrange(total_class)],\n",
    "                            key=lambda x:x[1])\n",
    "    if len(features) == 0:\n",
    "        return Tree(LEAF, Class = max_class)\n",
    "    \n",
    "    #Step3: calculate entropy\n",
    "    max_feature = 0\n",
    "    max_gda_ratio = 0 #g_r(D,A)\n",
    "    \n",
    "    D = train_label\n",
    "    H_D = calc_entropy(D)\n",
    "    \n",
    "    for feature in features:\n",
    "        #A = np.array(features[:,feature].flat)\n",
    "        A = np.array(train_set[:,feature].flat)\n",
    "        gda = H_D - calc_condition_entropy(A,D)\n",
    "        \n",
    "        split_information = split_info(A,D)\n",
    "        #print split_information\n",
    "        if split_information == 0:\n",
    "            continue\n",
    "        gda_ratio = gda/split_info(A,D)   #信息增益比\n",
    "        #print gda_ratio\n",
    "        \n",
    "        if gda_ratio > max_gda_ratio:\n",
    "            max_gda_ratio = gda_ratio\n",
    "            max_feature = feature\n",
    "    \n",
    "    #Step4:entropy 小于阈值的情况\n",
    "    if max_gda_ratio < epsilon:\n",
    "        return Tree(LEAF,Class = max_class)\n",
    "    \n",
    "    #Step5:构建非空子集\n",
    "    sub_features = filter(lambda x:x!= max_feature, features)\n",
    "    tree = Tree(INTERNAL, feature=max_feature)\n",
    "    \n",
    "    feature_col = np.array(train_set[:,max_feature].flat) #max feature\n",
    "    features_value_list = set([feature_col[i] for i in range(feature_col.shape[0])]) #信息增益最大特征A_g的每一可能值a_i\n",
    "    \n",
    "    for feature_value in features_value_list:\n",
    "        index = []\n",
    "        for i in xrange(len(train_label)):\n",
    "            if train_set[i][max_feature] == feature_value:\n",
    "                index.append(i)\n",
    "        \n",
    "        sub_train_set= train_set[index]\n",
    "        sub_train_label = train_label[index]\n",
    "        \n",
    "        sub_tree = recurse_train(sub_train_set,sub_train_label,sub_features,epsilon)\n",
    "        tree.add_tree(feature_value,sub_tree)\n",
    "        \n",
    "    return tree  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@log\n",
    "def predict(test_set,tree):\n",
    "    result = []\n",
    "    \n",
    "    for feature in test_set:\n",
    "        temp_prediction = tree.predict(feature)\n",
    "        result.append(temp_prediction)\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not see much difference, probably since dataset do not have many labels. Also features are pretty much 'discrete'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:start train()\n",
      "/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:12: RuntimeWarning: divide by zero encountered in log2\n",
      "DEBUG:root:end train(), cost 0.456895828247 seconds\n",
      "DEBUG:root:start predict()\n",
      "DEBUG:root:end predict(), cost 0.00173211097717 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruacy socre is  0.121212121212\n"
     ]
    }
   ],
   "source": [
    "tree = train(train_features,train_labels,[i for i in range(784)],0.01)\n",
    "test_predict = predict(test_features,tree)\n",
    "score = accuracy_score(test_labels,test_predict)\n",
    "\n",
    "print \"The accruacy socre is \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
