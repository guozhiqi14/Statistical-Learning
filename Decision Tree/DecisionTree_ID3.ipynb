{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        logging.debug('start %s()' % func.__name__)\n",
    "        ret = func(*args, **kwargs)\n",
    "        \n",
    "        end_time= time.time()\n",
    "        logging.debug('end %s(), cost %s seconds' % (func.__name__, end_time-start_time))\n",
    "        \n",
    "        return ret\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    raw_data = pd.read_csv('/Users/guozhiqi-seven/Documents/Statistical Learning/Decision Tree/train.csv',header=0) \n",
    "    data = raw_data.values\n",
    "    \n",
    "    img = data[:,1:]\n",
    "    labels = data[:,0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#直接用二值化之后的dataset (cv2 under python3 is available)\n",
    "features = np.loadtxt('features.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2/3 Training set\n",
    "#1/3 Testing  set\n",
    "train_features,test_features,train_labels,test_labels = train_test_split(features,labels,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self,node_type,Class=None,feature=None):\n",
    "        self.node_type = node_type\n",
    "        self.Class = Class\n",
    "        self.feature = feature\n",
    "        self.dict = {}  #不需要构造新的数据类型来存储决策树，使用字典dict即可方便的存储节点信息\n",
    "    def add_tree(self,val,tree):\n",
    "        self.dict[val]=tree\n",
    "    def predict(self,features):\n",
    "        if self.node_type == 'leaf':\n",
    "            return self.Class\n",
    "        tree = self.dict[features[self.feature]]\n",
    "        \n",
    "        return tree.predict(features)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(x):\n",
    "    '''\n",
    "    calculate entropy\n",
    "    x: labels\n",
    "    '''\n",
    "    \n",
    "    #H(X) = -sum(p_i * log(p_i))\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    entropy = 0.0\n",
    "    \n",
    "    for x_value in x_value_list:\n",
    "        p = float(x[x==x_value].shape[0]) / x.shape[0]\n",
    "        log_p = np.log2(p)\n",
    "        \n",
    "        entropy -= p*log_p\n",
    "    \n",
    "    return entropy #return啊你倒是return啊你妹..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_condition_entropy(x,y):\n",
    "    '''\n",
    "    conditional entropy H(y|x)\n",
    "    \n",
    "    x:feature\n",
    "    y:label\n",
    "    '''\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    entropy = 0.0\n",
    "    \n",
    "    for x_value in x_value_list:\n",
    "        sub_y = y[x==x_value]\n",
    "        temp_entropy = calc_entropy(sub_y)\n",
    "        entropy += (float(sub_y.shape[0]) / y.shape[0]) * temp_entropy\n",
    "    \n",
    "    return entropy #return啊你倒是return啊你妹...\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy_g(x,y):\n",
    "    '''\n",
    "    g(D,A) = H(D) - H(D|A)\n",
    "    '''\n",
    "    base_entropy = calc_entropy(y)\n",
    "    condition_entropy = calc_condition_entropy(x,y)\n",
    "    \n",
    "    entropy_g = base_entropy - condition_entropy\n",
    "    \n",
    "    return entropy_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@log\n",
    "def train(train_set,train_label,features,epsilon):\n",
    "    return recurse_train(train_set,train_label,features,epsilon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurse_train(train_set,train_label,features,epsilon):\n",
    "    global total_class\n",
    "    \n",
    "    LEAF = 'leaf'\n",
    "    INTERNAL = 'internal'\n",
    "    \n",
    "    #Step1: 如果train_set所有实例属于同一类C_k\n",
    "    label_set = set(train_label)\n",
    "    \n",
    "    if len(label_set) == 1:\n",
    "        return Tree(LEAF,Class = label_set.pop())\n",
    "    \n",
    "    #Step2: 如果feature为空\n",
    "    (max_class,max_len)=max([(i,len(filter(lambda x: x==i, train_label))) for i in xrange(total_class)],\n",
    "                            key=lambda x:x[1])\n",
    "    if len(features) == 0:\n",
    "        return Tree(LEAF, Class = max_class)\n",
    "    \n",
    "    #Step3: calculate entropy\n",
    "    max_feature = 0\n",
    "    max_gda = 0 #g(D,A)\n",
    "    \n",
    "    D = train_label\n",
    "    H_D = calc_entropy(D)\n",
    "    \n",
    "    for feature in features:\n",
    "        #A = np.array(features[:,feature].flat)\n",
    "        A = np.array(train_set[:,feature].flat)\n",
    "        gda = H_D - calc_condition_entropy(A,D)\n",
    "        \n",
    "        if gda > max_gda:\n",
    "            max_gda = gda\n",
    "            max_feature = feature\n",
    "    \n",
    "    #Step4:entropy 小于阈值的情况\n",
    "    if max_gda < epsilon:\n",
    "        return Tree(LEAF,Class = max_class)\n",
    "    \n",
    "    #Step5:构建非空子集\n",
    "    sub_features = filter(lambda x:x!= max_feature, features)\n",
    "    tree = Tree(INTERNAL, feature=max_feature)\n",
    "    \n",
    "    feature_col = np.array(train_set[:,max_feature].flat) #max feature\n",
    "    features_value_list = set([feature_col[i] for i in range(feature_col.shape[0])]) #信息增益最大特征A_g的每一可能值a_i\n",
    "    \n",
    "    for feature_value in features_value_list:\n",
    "        index = []\n",
    "        for i in xrange(len(train_label)):\n",
    "            if train_set[i][max_feature] == feature_value:\n",
    "                index.append(i)\n",
    "        \n",
    "        sub_train_set= train_set[index]\n",
    "        sub_train_label = train_label[index]\n",
    "        \n",
    "        sub_tree = recurse_train(sub_train_set,sub_train_label,sub_features,epsilon)\n",
    "        tree.add_tree(feature_value,sub_tree)\n",
    "        \n",
    "    return tree  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@log\n",
    "def predict(test_set,tree):\n",
    "    result = []\n",
    "    \n",
    "    for feature in test_set:\n",
    "        temp_prediction = tree.predict(feature)\n",
    "        result.append(temp_prediction)\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:start train()\n",
      "DEBUG:root:end train(), cost 198.132023096 seconds\n",
      "DEBUG:root:start predict()\n",
      "DEBUG:root:end predict(), cost 0.181843996048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruacy socre is  0.859812409812\n"
     ]
    }
   ],
   "source": [
    "tree = train(train_features,train_labels,[i for i in range(784)],0.1)\n",
    "test_predict = predict(test_features,tree)\n",
    "score = accuracy_score(test_labels,test_predict)\n",
    "\n",
    "print \"The accruacy socre is \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
